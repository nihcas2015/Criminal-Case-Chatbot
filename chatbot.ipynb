{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "349d4443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.chains import ConversationChain\n",
    "from typing import Optional, List, Any\n",
    "import faiss\n",
    "import json\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30d4ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db008976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_index_and_meta(index_path, meta_path):\n",
    "    index = faiss.read_index(index_path)\n",
    "    with open(meta_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        meta = json.load(f)\n",
    "    return index, meta\n",
    "\n",
    "def search_faiss(query, index, meta, top_k=2):\n",
    "    query_vec = embedder.encode([query])\n",
    "    query_vec = np.array(query_vec).astype(\"float32\")\n",
    "    D, I = index.search(query_vec, top_k)\n",
    "    results = []\n",
    "    for idx in I[0]:\n",
    "        if idx < len(meta):\n",
    "            results.append(meta[idx])\n",
    "    return results\n",
    "class ollama(LLM):\n",
    "    model_name: str = \"mistral\"\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"ollama\"\n",
    "    \n",
    "    def _call(self,prompt: str, stop: Optional[List[str]] = None, **kwargs: Any):\n",
    "        response = requests.post(\n",
    "        \"http://127.0.0.1:11434/api/generate\",\n",
    "        json={\"model\": self.model_name, \"prompt\": prompt, \"stream\": False}\n",
    "    )\n",
    "        return response.json()[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d924f68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipc_index, ipc_meta = load_index_and_meta(\"ipc.index\", \"ipc.json\")\n",
    "judg_index, judg_meta = load_index_and_meta(\"judgments.index\", \"judgments.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d2f7be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom=PromptTemplate(input_variables=[\"history\",\"input\"],template=\"\"\" You are an legal Chatbot assistant specializing in India Penal Code.\n",
    "                      \n",
    "                      Previous conversations:{history}\n",
    "                      \n",
    "                      Current question and also judgements :{input}\n",
    "                      \n",
    "                    provide an suitable reply for the current question by utilizing previous conversations, keep it around 20 to 30 words .\n",
    "                      Utilize similar case judgement and compare it with the user case summary and reply but do not repeat about judgement in every replies.\n",
    "                      Only use these given text as knowledge and reply with that knowledge DONT Retrieve your own knowledge\n",
    "                     Only talk about legal replies DO NOT REPLY ANY QUESTIONS WHICH ARE OUT OF INDIAN PENAL CODE .\n",
    "                      Don't reply to refer for an legal advisor\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbc7d832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihca\\AppData\\Local\\Temp\\ipykernel_14452\\3123097401.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory=ConversationBufferMemory()\n",
      "C:\\Users\\nihca\\AppData\\Local\\Temp\\ipykernel_14452\\3123097401.py:3: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  conversion = ConversationChain(llm=llm,memory=memory,prompt=custom,verbose=False)\n"
     ]
    }
   ],
   "source": [
    "llm=ollama()\n",
    "memory=ConversationBufferMemory()\n",
    "conversion = ConversationChain(llm=llm,memory=memory,prompt=custom,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "875ecf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚖️ IPC + Judgement Chatbot (type 'exit' to quit)\n",
      "\n",
      "\n",
      "Bot:  Based on the user's query, it seems like they might have committed an act that could fall under Section 302 of the Indian Penal Code (IPC), which pertains to murder.\n",
      "\n",
      "Section 302 IPC defines murder as the intentional causing of death or such bodily injury as is likely to cause death, with the intention of causing death, or with the knowledge that it is likely to cause death. The punishment for murder under Section 302 of the IPC is imprisonment for life, which means imprisonment until the convict's death.\n",
      "\n",
      "However, since the user's query suggests a history of daily torture and ragging, there could potentially be additional charges filed based on other sections as well. The acts of ragging or torturing others are criminal offenses under Section 326 (voluntarily causing grievous hurt) or even Section 307 (attempt to murder), depending on the severity and frequency of the actions mentioned.\n",
      "\n",
      "It is essential to stress that this response should not be considered as legal advice but only a general interpretation based on provided information. For accurate guidance, it is always best to consult with a qualified legal professional.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"⚖️ IPC + Judgement Chatbot (type 'exit' to quit)\\n\")\n",
    "\n",
    "user_input = input(\"You: \").strip()\n",
    "\n",
    "\n",
    "ipc_results = search_faiss(user_input, ipc_index, ipc_meta)\n",
    "judg_results = search_faiss(user_input, judg_index, judg_meta)\n",
    "\n",
    "        # Step 2: Build context\n",
    "context = \"Relevant IPC Sections:\\n\"\n",
    "for sec in ipc_results:\n",
    "    context += f\"- Section {sec['section_no']}: {sec['Description']} (Punishment: {sec['punishment_raw']})\\n\"\n",
    "\n",
    "prompt = f\"User Query: {user_input}\\n\\n{context}\\n\\nBased on the above IPC sections, Name the sections relating to the user query and also list possible punishments.\"\n",
    "Reply_1=llm._call(prompt)\n",
    "\n",
    "context += \"\\nRelevant Judgements:\\n\"\n",
    "for case in judg_results:\n",
    "    context += f\"\"\"- Case facts: {case['case_facts']}\n",
    "Issues: {case['issues']}\n",
    "Arguments: {case['arguments']}\n",
    "Decision: {case['decision']}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nBot: {Reply_1}\\n\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca8260dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bot:  In the Indian Penal Code, intention to inflict a bodily injury sufficient to cause death, even if not intended, can lead to murder charges. Multiple injuries causing death due to public enmity have resulted in conviction (e.g., Rompicherla case). However, specific circumstances vary for each case. Consult a legal advisor for advice on your situation.\n",
      "\n",
      "Bot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"You: \").strip()\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Bot: Goodbye!\")\n",
    "        break\n",
    "\n",
    "    user_input+=f\"\\n\\n similar case judgements : {context}\"\n",
    "\n",
    "    answer = conversion.predict(input=user_input)\n",
    "\n",
    "    print(f\"\\nBot: {answer}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
