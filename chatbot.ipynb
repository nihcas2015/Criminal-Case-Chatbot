{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "349d4443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.chains import ConversationChain\n",
    "from typing import Optional, List, Any\n",
    "import faiss\n",
    "import json\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30d4ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db008976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_index_and_meta(index_path, meta_path):\n",
    "    index = faiss.read_index(index_path)\n",
    "    with open(meta_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        meta = json.load(f)\n",
    "    return index, meta\n",
    "\n",
    "def search_faiss(query, index, meta, top_k=2):\n",
    "    query_vec = embedder.encode([query])\n",
    "    query_vec = np.array(query_vec).astype(\"float32\")\n",
    "    D, I = index.search(query_vec, top_k)\n",
    "    results = []\n",
    "    for idx in I[0]:\n",
    "        if idx < len(meta):\n",
    "            results.append(meta[idx])\n",
    "    return results\n",
    "class ollama(LLM):\n",
    "    model_name: str = \"mistral\"\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"ollama\"\n",
    "    \n",
    "    def _call(self,prompt: str, stop: Optional[List[str]] = None, **kwargs: Any):\n",
    "        response = requests.post(\n",
    "        \"http://127.0.0.1:11434/api/generate\",\n",
    "        json={\"model\": self.model_name, \"prompt\": prompt, \"stream\": False}\n",
    "    )\n",
    "        return response.json()[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d924f68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipc_index, ipc_meta = load_index_and_meta(\"ipc.index\", \"ipc.json\")\n",
    "judg_index, judg_meta = load_index_and_meta(\"judgments.index\", \"judgments.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2f7be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom=PromptTemplate(input_variables=[\"history\",\"input\"],template=\"\"\" You are an legal Chatbot assistant specializing in India Penal Code.\n",
    "                      \n",
    "                      Previous conversations:{history}\n",
    "                      \n",
    "                      Current question and also judgements :{input}\n",
    "                      \n",
    "                    provide an suitable reply for the current question by utilizing previous conversations and keep it around 20 to 30 words .\n",
    "                      Utilize similar case judgement and compare it with the user case summary and then reply but do not repeat about judgements in every replies.\n",
    "                      Only use the given text as knowledge, Do Not Retrieve your own knowledge\n",
    "                      Only Reply using the given IPC sections, STICK TO ONLY THIS TEXT AND PREVIOUS CONVERSATION FOR KNOWLEDGE.\n",
    "                      Consider youself as an legal advisor and you are the professional.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbc7d832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihca\\AppData\\Local\\Temp\\ipykernel_4152\\3123097401.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory=ConversationBufferMemory()\n",
      "C:\\Users\\nihca\\AppData\\Local\\Temp\\ipykernel_4152\\3123097401.py:3: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  conversion = ConversationChain(llm=llm,memory=memory,prompt=custom,verbose=False)\n"
     ]
    }
   ],
   "source": [
    "llm=ollama()\n",
    "memory=ConversationBufferMemory()\n",
    "conversion = ConversationChain(llm=llm,memory=memory,prompt=custom,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "875ecf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚖️ IPC + Judgement Chatbot (type 'exit' to quit)\n",
      "\n",
      "\n",
      "Bot:  Based on the user's query, the relevant Indian Penal Code (IPC) sections that could potentially apply are:\n",
      "\n",
      "1. Section 324 - Voluntarily causing hurt by dangerous weapons or means: This section might apply because the user admitted to killing their friend, which could be interpreted as causing hurt voluntarily. The punishment for this section includes imprisonment for a term extending up to three years, fine, or both.\n",
      "\n",
      "2. Section 302 - Murder: If the act of causing harm resulted in death, then Section 302 might also apply. However, it's important to note that intent is a crucial factor in determining whether an act falls under this section. In this case, if the user intentionally caused their friend's death, they could be charged with murder, which carries a maximum punishment of death or life imprisonment.\n",
      "\n",
      "3. Section 304- Part I - Causing death by rash or negligent act: If the harm was caused without the intent to kill but recklessly, this section might apply. The punishment for this section includes imprisonment up to ten years, and a fine.\n",
      "\n",
      "Please remember that I am an AI model and my responses are based on the information provided in the Indian Penal Code. It's essential to consult with legal professionals to interpret laws accurately and understand the specific circumstances of each case.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"⚖️ IPC + Judgement Chatbot (type 'exit' to quit)\\n\")\n",
    "\n",
    "user_input = input(\"You: \").strip()\n",
    "\n",
    "\n",
    "ipc_results = search_faiss(user_input, ipc_index, ipc_meta)\n",
    "judg_results = search_faiss(user_input, judg_index, judg_meta)\n",
    "\n",
    "        # Step 2: Build context\n",
    "context = \"Relevant IPC Sections:\\n\"\n",
    "for sec in ipc_results:\n",
    "    context += f\"- Section {sec['section_no']}: {sec['Description']} (Punishment: {sec['punishment_raw']})\\n\"\n",
    "\n",
    "prompt = f\"User Query: {user_input}\\n\\n{context}\\n\\nBased on the above IPC sections, Name the sections relating to the user query and also list possible punishments.\"\n",
    "Reply_1=llm._call(prompt)\n",
    "\n",
    "context += \"\\nRelevant Judgements:\\n\"\n",
    "for case in judg_results:\n",
    "    context += f\"\"\"- Case facts: {case['case_facts']}\n",
    "Issues: {case['issues']}\n",
    "Arguments: {case['arguments']}\n",
    "Decision: {case['decision']}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nBot: {Reply_1}\\n\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8260dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bot:  Based on the provided judgement, intentional harm resulting in death can be punishable under IPC Section 302 or 324. Circumstantial evidence can support a conviction if it forms a clear and unambiguous chain proving your involvement. Be aware that any intentional harm could lead to legal consequences.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"You: \").strip()\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Bot: Goodbye!\")\n",
    "        break\n",
    "\n",
    "    user_input+=f\"\\n\\n similar case judgements : {context}\"\n",
    "\n",
    "    answer = conversion.predict(input=user_input)\n",
    "\n",
    "    print(f\"\\nBot: {answer}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
