{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "349d4443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.chains import ConversationChain\n",
    "from typing import Optional, List, Any\n",
    "import faiss\n",
    "import json\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30d4ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer(\"bhavyagiri/InLegal-Sbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db008976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_index_and_meta(index_path, meta_path):\n",
    "    index = faiss.read_index(index_path)\n",
    "    with open(meta_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        meta = json.load(f)\n",
    "    return index, meta\n",
    "\n",
    "def search_faiss(query, index, meta, top_k=2):\n",
    "    query_vec = embedder.encode([query])\n",
    "    query_vec = np.array(query_vec).astype(\"float32\")\n",
    "    D, I = index.search(query_vec, top_k)\n",
    "    results = []\n",
    "    for idx in I[0]:\n",
    "        if idx < len(meta):\n",
    "            results.append(meta[idx])\n",
    "    return results\n",
    "class ollama(LLM):\n",
    "    model_name: str = \"mistral\"\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"ollama\"\n",
    "    \n",
    "    def _call(self,prompt: str, stop: Optional[List[str]] = None, **kwargs: Any):\n",
    "        response = requests.post(\n",
    "        \"http://127.0.0.1:11434/api/generate\",\n",
    "        json={\"model\": self.model_name, \"prompt\": prompt, \"stream\": False}\n",
    "    )\n",
    "        return response.json()[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d924f68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipc_index, ipc_meta = load_index_and_meta(\"ipc.index\", \"ipc.json\")\n",
    "judg_index, judg_meta = load_index_and_meta(\"judgments.index\", \"judgments.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d2f7be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom=PromptTemplate(input_variables=[\"history\",\"input\"],template=\"\"\" You are an legal Chatbot assistant specializing in India Penal Code.\n",
    "                      \n",
    "                      Previous conversations:{history}\n",
    "                      \n",
    "                      Current question and also judgements :{input}\n",
    "                      \n",
    "                    provide an suitable reply for the current question by utilizing previous conversations and keep it around 20 to 30 words .\n",
    "                      Utilize similar case judgement and compare it with the user case summary and then reply but do not repeat about judgements in every replies.\n",
    "                      Only use the given text as knowledge, Do Not Retrieve your own knowledge\n",
    "                      Only Reply using the given IPC sections, STICK TO ONLY THIS TEXT AND PREVIOUS CONVERSATION FOR KNOWLEDGE.\n",
    "                      Consider youself as an legal advisor and you are the professional.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbc7d832",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ollama()\n",
    "memory=ConversationBufferMemory()\n",
    "conversion = ConversationChain(llm=llm,memory=memory,prompt=custom,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "875ecf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚖️ IPC + Judgement Chatbot (type 'exit' to quit)\n",
      "\n",
      "\n",
      "Bot:  Based on the user's query, it appears that the act described falls under Section 375 of the Indian Penal Code (IPC), which pertains to rape. The specific sub-section would be:\n",
      "\n",
      "1. Rape - Against her will.\n",
      "2. Rape - Without her consent.\n",
      "\n",
      "As for punishments, the Criminal Law (Amendment) Act, 2013 states that a man found guilty of rape may be punished with imprisonment ranging from 7 years up to life, and shall also be liable to fine. In certain circumstances such as when the victim is a child or the act was particularly brutal or cruel, the punishment may extend to death (capital punishment).\n",
      "\n",
      "It's important to note that this information provided is for educational purposes only and should not be used as legal advice. If you find yourself in a similar situation, it's crucial to consult with a legal professional for proper guidance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"⚖️ IPC + Judgement Chatbot (type 'exit' to quit)\\n\")\n",
    "\n",
    "user_input = input(\"You: \").strip()\n",
    "\n",
    "\n",
    "ipc_results = search_faiss(user_input, ipc_index, ipc_meta)\n",
    "judg_results = search_faiss(user_input, judg_index, judg_meta)\n",
    "\n",
    "        # Step 2: Build context\n",
    "context = \"Relevant IPC Sections:\\n\"\n",
    "for sec in ipc_results:\n",
    "    context += f\"- Section {sec['section_no']}: {sec['Description']} (Punishment: {sec['punishment_raw']})\\n\"\n",
    "\n",
    "prompt = f\"User Query: {user_input}\\n\\n{context}\\n\\nBased on the above IPC sections, Name the sections relating to the user query and also list possible punishments.\"\n",
    "Reply_1=llm._call(prompt)\n",
    "\n",
    "context += \"\\nRelevant Judgements:\\n\"\n",
    "for case in judg_results:\n",
    "    context += f\"\"\"- Case facts: {case['case_facts']}\n",
    "Issues: {case['issues']}\n",
    "Arguments: {case['arguments']}\n",
    "Decision: {case['decision']}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nBot: {Reply_1}\\n\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca8260dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"You: \").strip()\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Bot: Goodbye!\")\n",
    "        break\n",
    "\n",
    "    user_input+=f\"\\n\\n similar case judgements : {context}\"\n",
    "\n",
    "    answer = conversion.predict(input=user_input)\n",
    "\n",
    "    print(f\"\\nBot: {answer}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
