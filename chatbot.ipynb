{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "349d4443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.chains import ConversationChain\n",
    "from typing import Optional, List, Any\n",
    "import faiss\n",
    "import json\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30d4ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer(\"bhavyagiri/InLegal-Sbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db008976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_index_and_meta(index_path, meta_path):\n",
    "    index = faiss.read_index(index_path)\n",
    "    with open(meta_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        meta = json.load(f)\n",
    "    return index, meta\n",
    "\n",
    "def search_faiss(query, index, meta, top_k=2):\n",
    "    query_vec = embedder.encode([query])\n",
    "    query_vec = np.array(query_vec).astype(\"float32\")\n",
    "    D, I = index.search(query_vec, top_k)\n",
    "    results = []\n",
    "    for idx in I[0]:\n",
    "        if idx < len(meta):\n",
    "            results.append(meta[idx])\n",
    "    return results\n",
    "class ollama(LLM):\n",
    "    model_name: str = \"mistral\"\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"ollama\"\n",
    "        \n",
    "    def _call(self,prompt: str, stop: Optional[List[str]] = None, **kwargs: Any):\n",
    "        response = requests.post(\n",
    "            \"http://127.0.0.1:11434/api/generate\",\n",
    "            json={\"model\": self.model_name, \"prompt\": prompt, \"stream\": False}\n",
    "        )\n",
    "        return response.json()[\"response\"]\n",
    "\n",
    "def get_top_judgment_text(query):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"}\n",
    "    url = f\"https://indiankanoon.org/search/?formInput={query}&type=judgement\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    results = soup.find_all(\"div\", class_=\"result_title\")\n",
    "    for result in results:\n",
    "        link_tag = result.find('a')\n",
    "        if not link_tag:\n",
    "            continue\n",
    "        link = link_tag['href']\n",
    "        full_link = \"https://indiankanoon.org\" + link\n",
    "        judgment_page = requests.get(full_link, headers=headers)\n",
    "        judgment_soup = BeautifulSoup(judgment_page.text, 'html.parser')\n",
    "        judgment_div = judgment_soup.find(\"div\", {\"id\": \"judgment\"})\n",
    "        if judgment_div:\n",
    "            judgment_text = judgment_div.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            judgment_text = judgment_soup.get_text(separator=\"\\n\", strip=True)\n",
    "        return judgment_text\n",
    "    return None\n",
    "def summarize_long_text(text, tokenizer, model, chunk_size=1024, overlap=100):\n",
    "    # Split into words for rough chunking\n",
    "    words = text.split()\n",
    "    summaries = []\n",
    "\n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = \" \".join(words[i:i + chunk_size])\n",
    "        inputs = tokenizer(chunk, return_tensors=\"pt\", max_length=chunk_size, truncation=True)\n",
    "        summary_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_length=200,\n",
    "            num_beams=4,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        summaries.append(tokenizer.decode(summary_ids[0], skip_special_tokens=True))\n",
    "\n",
    "    # Optionally combine and summarize again for final condensation\n",
    "    combined_summary = \" \".join(summaries)\n",
    "    final_inputs = tokenizer(combined_summary, return_tensors=\"pt\", truncation=True)\n",
    "    final_summary_ids = model.generate(\n",
    "        **final_inputs,\n",
    "        max_length=300,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    return tokenizer.decode(final_summary_ids[0], skip_special_tokens=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d924f68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipc_index, ipc_meta = load_index_and_meta(\"ipc.index\", \"ipc.json\")\n",
    "\n",
    "model_dir = \"./legal_summarizer_model\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d2f7be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom=PromptTemplate(input_variables=[\"history\",\"input\"],template=\"\"\" You are an legal Chatbot assistant specializing in India Penal Code.\n",
    "                      \n",
    "                      Previous conversations:{history}\n",
    "                      \n",
    "                      Current question and also similar judgements :{input}\n",
    "                      \n",
    "                      Read user query carefully and Speak to them like an chatbot.\n",
    "                      Utilize judgements given and also previous conversations for your knowledge.\n",
    "                      DO NOT REPEAT ABOUT THE SAME JUDGEMENT FOR EVERY REPLY \n",
    "                      BE CONCISE BUT ALSO SPEAK WELL.\n",
    "                      DO NOT HALLUCINATE WITH YOUR LEGAL KNOWLEDGE.\n",
    "                      CONSIDER YOURSELF WELL TRAINED LEGAL CHATBOT.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbc7d832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nihca\\AppData\\Local\\Temp\\ipykernel_26792\\3123097401.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory=ConversationBufferMemory()\n",
      "C:\\Users\\nihca\\AppData\\Local\\Temp\\ipykernel_26792\\3123097401.py:3: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  conversion = ConversationChain(llm=llm,memory=memory,prompt=custom,verbose=False)\n"
     ]
    }
   ],
   "source": [
    "llm=ollama()\n",
    "memory=ConversationBufferMemory()\n",
    "conversion = ConversationChain(llm=llm,memory=memory,prompt=custom,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "875ecf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚖️ IPC + Judgement Chatbot (type 'exit' to quit)\n",
      "\n",
      "Bot:  In India, the Indian Penal Code (IPC) Section 80 discusses accidents in doing a lawful act. If you've accidentally caused harm, such as driving under the influence and causing an accident, without any criminal intention or knowledge, it may be considered excusable if proper care and caution were taken. However, this does not mean you are completely exempt from legal consequences.\n",
      "\n",
      "IPC Section 159 defines affray as two or more persons fighting in a public place that disturbs the peace. This could potentially apply if multiple people are involved in an altercation due to your actions.\n",
      "\n",
      "Remember, every case is unique and the outcome depends on various factors such as evidence, intent, and specific circumstances. It's crucial to consult with a legal professional for advice tailored to your situation. I'm here to help guide you, but my responses should not be taken as legal advice.\n",
      "Bot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "print(\"⚖️ IPC + Judgement Chatbot (type 'exit' to quit)\\n\")\n",
    "\n",
    "user_input = input(\"You: \").strip()\n",
    "\n",
    "\n",
    "ipc_results = search_faiss(user_input, ipc_index, ipc_meta)\n",
    "context = f\"User query : {user_input} \\n \"\n",
    "for item in ipc_results:\n",
    "    context+=f\"\\nIPC \\n {item['section_no']} \\n Description:{item['Description']} \\n Punishments : {item['punishment_raw']} \\n Judgement Summary: \\n\"\n",
    "    if 'section_no' in item and ':-' in item['section_no']:\n",
    "        item['section_no'] = item['section_no'].split(':-', 1)[1].strip()\n",
    "        context += summarize_long_text(get_top_judgment_text(item[\"section_no\"]), tokenizer, model)\n",
    "\n",
    "\n",
    "print(\"Bot:\",conversion.predict(input=context))\n",
    "while True:\n",
    "    user_input = input(\"You: \").strip()\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Bot: Goodbye!\")\n",
    "        break\n",
    "\n",
    "    answer = conversion.predict(input=user_input)\n",
    "\n",
    "    print(f\"\\nBot: {answer}\\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59e9847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43ef36d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User query : i killed someone while drunk driving \n",
      " \n",
      "IPC \n",
      " Section80:- Accident in doing a lawful act \n",
      " Description:Nothing is an offence which is done by accident or misfortune, and without any criminal intention or knowledge in the doing of a lawful act in a lawful manner by lawful means and with proper care and caution. Illustrations A is at work with a hatchet; the head flies off and kills a man who is standing by. Here, if there was no want of proper caution on the part of A, his act is excusable and not an offence. \n",
      " Punishments :  \n",
      " Judgement Summary: \n",
      "The first respondent B purchased a Touzi in 24 Parganas Collectorate at a revenue sale held on 9th January 1942. As such purchaser he acquired under section 37 of the Bengal Revenue Sales Act 1859 the right \"to avoid and annul all under tenures and forthwith to eject all under tenants\" with certain exceptions which are not material here. In exercise of that right he gave notices of ejectment and brought a suit in 1946 to evict certain under tenants including the second respondent herein and to recover possession of the lands. The suit was decreed against the second respondent who preferred an appeal to the District Judge 24 Parganas contending that his under tenure came within one of the exceptions referred to in section 37. When the appeal was pending the Bill which was later passed as the West Bengal Revenue Sales (West Bengal Amendment) Act 1950 was introduced in the West Bengal Legislative ASsembly on 23rd March 1950. It would appear according to the \"statement of objects and reasons\" annexed to the Bill that great hardship was being caused to a large section of the people by the application of section 37\n",
      "IPC \n",
      " Section159:- Affray \n",
      " Description:When two or more persons, by fighting in a public place, disturb the public peace, they are said to \"commit an affray\". \n",
      " Punishments :  \n",
      " Judgement Summary: \n",
      "These petitions on behalf of certain newspaper establishments challenged the constitutional validity of the Working journalists (Conditions of Service) and Miscellaneous Provisions Act 1955 and the legality of the decision of the Wage Board constituted thereunder purporting to act under section 9 of the Act. The impugned Act which was passed in order to implement the recommendations of the Press Commission and had for its object the regulation of the conditions of service of working journalists and other persons employed in newspaper establishments provided inter alia for the payment of gratuity to a working journalist who had been in continuous service whether before or after the commencement of the Act for not less than three years even when he voluntarily resigned from service regulated hours of work and leave provided for the payment of retrenchment compensation with retrospective effect in certain cases and by section 9(1) laid down the principles that the Wage Board was to follow in fixing the rates of wages of working journalists. Under those principles the Wage Board was to have regard to the cost of living the prevalent rates of wages for comparable employments the circumstances relating to the newspaper industry in different regions of the country and to any other circumstances which it might consider relevant. The petition\n"
     ]
    }
   ],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "369bec61",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='indiankanoon.org', port=443): Max retries exceeded with url: /search/?formInput=Affray&type=judgement (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001BE422EFCA0>: Failed to resolve 'indiankanoon.org' ([Errno 11001] getaddrinfo failed)\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\urllib3\\connection.py:198\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 198\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\urllib3\\util\\connection.py:60\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LocationParseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label empty or too long\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     61\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\socket.py:967\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    966\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 967\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    968\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNameResolutionError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    788\u001b[0m     conn,\n\u001b[0;32m    789\u001b[0m     method,\n\u001b[0;32m    790\u001b[0m     url,\n\u001b[0;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\urllib3\\connectionpool.py:488\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    487\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[1;32m--> 488\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[0;32m    490\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\urllib3\\connectionpool.py:464\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 464\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\urllib3\\connectionpool.py:1093\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m-> 1093\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\urllib3\\connection.py:753\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    752\u001b[0m sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[1;32m--> 753\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    754\u001b[0m server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\urllib3\\connection.py:205\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mNameResolutionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x000001BE422EFCA0>: Failed to resolve 'indiankanoon.org' ([Errno 11001] getaddrinfo failed)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\requests\\adapters.py:644\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 644\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    839\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 841\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    844\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\urllib3\\util\\retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='indiankanoon.org', port=443): Max retries exceeded with url: /search/?formInput=Affray&type=judgement (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001BE422EFCA0>: Failed to resolve 'indiankanoon.org' ([Errno 11001] getaddrinfo failed)\"))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m summary \u001b[38;5;241m=\u001b[39m tokenizer(\u001b[43mget_top_judgment_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msection_no\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[3], line 33\u001b[0m, in \u001b[0;36mget_top_judgment_text\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m     31\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMozilla/5.0 (Windows NT 10.0; Win64; x64)\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     32\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://indiankanoon.org/search/?formInput=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&type=judgement\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 33\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     35\u001b[0m results \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult_title\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32md:\\anaconda\\envs\\ml\\lib\\site-packages\\requests\\adapters.py:677\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    673\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    674\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    675\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='indiankanoon.org', port=443): Max retries exceeded with url: /search/?formInput=Affray&type=judgement (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001BE422EFCA0>: Failed to resolve 'indiankanoon.org' ([Errno 11001] getaddrinfo failed)\"))"
     ]
    }
   ],
   "source": [
    "summary = tokenizer(get_top_judgment_text(item[\"section_no\"]), return_tensors=\"pt\", max_length=1024, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "048cee26",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msummary\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'summary' is not defined"
     ]
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df7a7d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_ids = model.generate(\n",
    "    **summary,\n",
    "    max_length=200,   \n",
    "    num_beams=4,\n",
    "    early_stopping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d3e12da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first respondent B purchased a Touzi in 24 Parganas Collectorate at a revenue sale held on 9th January 1942. As such purchaser he acquired under section 37 of the Bengal Revenue Sales Act 1859 the right \"to avoid and annul all under tenures and forthwith to eject all under tenants\" with certain exceptions which are not material here. In exercise of that right he gave notices of ejectment and brought a suit in 1946 to evict certain under tenants including the second respondent herein and to recover possession of the lands. The suit was decreed against the second respondent who preferred an appeal to the District Judge 24 Parganas contending that his under tenure came within one of the exceptions referred to in section 37. When the appeal was pending the Bill which was later passed as the West Bengal Revenue Sales (West Bengal Amendment) Act 1950 was introduced in the West Bengal'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afab6501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Arun Singh vs State Of U.P. on 10 February, 2020\\nShare Link\\nMobile View\\nFree features\\nPremium features\\nCase removal\\nView Complete document\\nArun Singh vs State Of U.P. on 10 February, 2020\\nShowing the contexts in which\\nCohabitation caused by a man deceitfully inducing a belief of lawful marriage\\nappears in the document\\nChange context size\\nCurrent\\n“\\nCohabit\\na\\ntion\\ncaused\\nby\\na\\nman\\ndeceit\\nfully\\ninducing\\na\\nbelief\\nof\\nlaw\\nful\\nmarriage\\n. - Every\\nman\\nwho by\\ndeceit\\ncauses\\na\\nny\\n         wo\\nman\\nwho is not\\nlaw\\nfully m\\na\\nrried to him to believe th\\na\\nt she is\\nlaw\\nfully m\\na\\nrried to him\\na\\nnd to\\ncohabit\\nor h\\na\\nve sexu\\na\\nl\\n         intercourse with him in th\\na\\nt\\nbelief\\n, sh\\na\\nll be punished with\\n         imprisonment of either description for\\na\\nterm which m\\nay\\nextend\\n         to ten ye\\na\\nrs,\\na\\nnd sh\\na\\nll\\na\\nlso be li\\na\\nble to fine.”\\n18.\\nA\\npl\\na\\nin re\\na\\nding of the Section goes to show th\\na\\nt in order to constitute\\na\\nn offence under this Section, it h\\nas\\nto be demonstr\\nated\\nth\\na\\nt\\na\\nman\\nh\\nas\\ndeceit\\nfully\\ncaused\\na\\nny wo\\nman\\n, who is not\\nlaw\\nfully m\\na\\nrried to him, to believe\\n\\n\\nth\\na\\nt she is\\nlaw\\nfully m\\na\\nrried wife\\na\\nnd thereby co-h\\na\\nbit with him. In other\\n\\nwords, the\\na\\nccused must\\ninduce\\na\\nwo\\nman\\n, not\\nlaw\\nfully m\\na\\nrried to him, to\\n\\nbelieve th\\na\\nt she is m\\na\\nrried to him\\na\\nnd\\nas\\na\\nresult of such mis-represent\\na\\ntion,\\n\\nwo\\nman\\nshould believe th\\na\\nt she w\\nas\\nlaw\\nfully m\\na\\nrried to the\\nman\\na\\nnd thus there\\n\\nshould be co-h\\na\\nbit\\na\\ntion or sexu\\na\\nl intercourse.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_judgment_text(item[\"section_no\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed13a521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Arun Singh vs State Of U.P. on 10 February, 2020\\nShare Link\\nMobile View\\nFree features\\nPremium features\\nCase removal\\nView Complete document\\nArun Singh vs State Of U.P. on 10 February, 2020\\nShowing the contexts in which\\nCohabitation caused by a man deceitfully inducing a belief of lawful marriage\\nappears in the document\\nChange context size\\nCurrent\\n“\\nCohabit\\na\\ntion\\ncaused\\nby\\na\\nman\\ndeceit\\nfully\\ninducing\\na\\nbelief\\nof\\nlaw\\nful\\nmarriage\\n. - Every\\nman\\nwho by\\ndeceit\\ncauses\\na\\nny\\n         wo\\nman\\nwho is not\\nlaw\\nfully m\\na\\nrried to him to believe th\\na\\nt she is\\nlaw\\nfully m\\na\\nrried to him\\na\\nnd to\\ncohabit\\nor h\\na\\nve sexu\\na\\nl\\n         intercourse with him in th\\na\\nt\\nbelief\\n, sh\\na\\nll be punished with\\n         imprisonment of either description for\\na\\nterm which m\\nay\\nextend\\n         to ten ye\\na\\nrs,\\na\\nnd sh\\na\\nll\\na\\nlso be li\\na\\nble to fine.”\\n18.\\nA\\npl\\na\\nin re\\na\\nding of the Section goes to show th\\na\\nt in order to constitute\\na\\nn offence under this Section, it h\\nas\\nto be demonstr\\nated\\nth\\na\\nt\\na\\nman\\nh\\nas\\ndeceit\\nfully\\ncaused\\na\\nny wo\\nman\\n, who is not\\nlaw\\nfully m\\na\\nrried to him, to believe\\n\\n\\nth\\na\\nt she is\\nlaw\\nfully m\\na\\nrried wife\\na\\nnd thereby co-h\\na\\nbit with him. In other\\n\\nwords, the\\na\\nccused must\\ninduce\\na\\nwo\\nman\\n, not\\nlaw\\nfully m\\na\\nrried to him, to\\n\\nbelieve th\\na\\nt she is m\\na\\nrried to him\\na\\nnd\\nas\\na\\nresult of such mis-represent\\na\\ntion,\\n\\nwo\\nman\\nshould believe th\\na\\nt she w\\nas\\nlaw\\nfully m\\na\\nrried to the\\nman\\na\\nnd thus there\\n\\nshould be co-h\\na\\nbit\\na\\ntion or sexu\\na\\nl intercourse.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_judgment_text(item[\"section_no\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8260dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"You: \").strip()\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Bot: Goodbye!\")\n",
    "        break\n",
    "\n",
    "    \n",
    "\n",
    "    answer = conversion.predict(input=user_input)\n",
    "\n",
    "    print(f\"\\nBot: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dde3bbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ready with 10 test queries\n",
      "✅ Using evaluation model: bhavyagiri/InLegal-Sbert (your existing embedder)\n"
     ]
    }
   ],
   "source": [
    "# Test queries for evaluation\n",
    "test_queries = [\n",
    "    \"What is the punishment for murder?\",\n",
    "    \"Explain Section 302 IPC\",\n",
    "    \"What are the differences between theft and robbery?\",\n",
    "    \"Punishment for dowry death\",\n",
    "    \"What is culpable homicide?\",\n",
    "    \"Explain Section 420 IPC about cheating\",\n",
    "    \"What is the punishment for kidnapping?\",\n",
    "    \"Define Section 376 IPC\",\n",
    "    \"What are the provisions for defamation?\",\n",
    "    \"Explain attempt to murder under IPC\"\n",
    "]\n",
    "\n",
    "# Use the SAME model you're already using (no need to load a new one)\n",
    "eval_model = embedder  # Reuse your existing InLegal-Sbert model\n",
    "\n",
    "print(f\"✅ Ready with {len(test_queries)} test queries\")\n",
    "print(f\"✅ Using evaluation model: bhavyagiri/InLegal-Sbert (your existing embedder)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19db7f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RETRIEVAL CONSISTENCY\n",
      "============================================================\n",
      "\n",
      "Query: 'What is the punishment for murder?'\n",
      "📊 IPC Retrieval Consistent: ✅ YES\n",
      "📊 Judgement Retrieval Consistent: ✅ YES\n",
      "   Retrieved: ('Section302:- Punishment for murder', 'Section507:- Criminal intimidation by an anonymous communication')\n"
     ]
    }
   ],
   "source": [
    "# EVALUATION 1: RETRIEVAL CONSISTENCY\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RETRIEVAL CONSISTENCY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_query = \"What is the punishment for murder?\"\n",
    "num_runs = 5\n",
    "\n",
    "ipc_retrieved = []\n",
    "judg_retrieved = []\n",
    "\n",
    "for run in range(num_runs):\n",
    "    ipc_results = search_faiss(test_query, ipc_index, ipc_meta, top_k=2)\n",
    "    judg_results = search_faiss(test_query, judg_index, judg_meta, top_k=2)\n",
    "    \n",
    "    ipc_ids = tuple([r['section_no'] for r in ipc_results])\n",
    "    judg_ids = tuple([r['id'] for r in judg_results])\n",
    "    \n",
    "    ipc_retrieved.append(ipc_ids)\n",
    "    judg_retrieved.append(judg_ids)\n",
    "\n",
    "ipc_consistent = len(set(ipc_retrieved)) == 1\n",
    "judg_consistent = len(set(judg_retrieved)) == 1\n",
    "\n",
    "print(f\"\\nQuery: '{test_query}'\")\n",
    "print(f\"📊 IPC Retrieval Consistent: {'✅ YES' if ipc_consistent else '❌ NO'}\")\n",
    "print(f\"📊 Judgement Retrieval Consistent: {'✅ YES' if judg_consistent else '❌ NO'}\")\n",
    "print(f\"   Retrieved: {ipc_retrieved[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54b04f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ANSWER CONSISTENCY\n",
      "============================================================\n",
      "\n",
      "📊 Consistency Score: 0.970\n",
      "   Min Similarity: 0.964\n",
      "   Max Similarity: 0.976\n",
      "   ✅ HIGH consistency\n"
     ]
    }
   ],
   "source": [
    "# EVALUATION 2: ANSWER CONSISTENCY\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANSWER CONSISTENCY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_query = \"What is the punishment for murder?\"\n",
    "num_samples = 3\n",
    "\n",
    "answers = []\n",
    "for i in range(num_samples):\n",
    "    ipc_results = search_faiss(test_query, ipc_index, ipc_meta, top_k=2)\n",
    "    \n",
    "    context = \"Relevant IPC Sections:\\n\"\n",
    "    for sec in ipc_results:\n",
    "        context += f\"- Section {sec['section_no']}: {sec['Description']} (Punishment: {sec['punishment_raw']})\\n\"\n",
    "    \n",
    "    prompt = f\"User Query: {test_query}\\n\\n{context}\\n\\nBased on the above IPC sections, Name the sections relating to the user query and also list possible punishments.\"\n",
    "    answer = llm._call(prompt)\n",
    "    answers.append(answer)\n",
    "\n",
    "embeddings = eval_model.encode(answers, convert_to_tensor=True)\n",
    "similarities = []\n",
    "\n",
    "for i in range(len(answers)):\n",
    "    for j in range(i+1, len(answers)):\n",
    "        sim = util.cos_sim(embeddings[i], embeddings[j]).item()\n",
    "        similarities.append(sim)\n",
    "\n",
    "consistency_score = np.mean(similarities)\n",
    "\n",
    "print(f\"\\n📊 Consistency Score: {consistency_score:.3f}\")\n",
    "print(f\"   Min Similarity: {np.min(similarities):.3f}\")\n",
    "print(f\"   Max Similarity: {np.max(similarities):.3f}\")\n",
    "\n",
    "if consistency_score > 0.8:\n",
    "    print(f\"   ✅ HIGH consistency\")\n",
    "elif consistency_score > 0.6:\n",
    "    print(f\"   ⚠️ MODERATE consistency\")\n",
    "else:\n",
    "    print(f\"   ❌ LOW consistency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2eeb75c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CONTEXT RELEVANCE\n",
      "============================================================\n",
      "Query: What is the punishment for murder?... → Score: 0.659\n",
      "Query: Explain Section 302 IPC... → Score: 0.673\n",
      "Query: What are the differences between theft and robbery... → Score: 0.743\n",
      "Query: Punishment for dowry death... → Score: 0.698\n",
      "Query: What is culpable homicide?... → Score: 0.680\n",
      "\n",
      "📊 Mean Context Relevance: 0.691\n",
      "   Range: [0.659, 0.743]\n"
     ]
    }
   ],
   "source": [
    "# EVALUATION 3: CONTEXT RELEVANCE\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONTEXT RELEVANCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "relevance_scores = []\n",
    "\n",
    "for query in test_queries[:5]:\n",
    "    ipc_results = search_faiss(query, ipc_index, ipc_meta, top_k=2)\n",
    "    \n",
    "    context = \"Relevant IPC Sections:\\n\"\n",
    "    for sec in ipc_results:\n",
    "        context += f\"- Section {sec['section_no']}: {sec['Description']} (Punishment: {sec['punishment_raw']})\\n\"\n",
    "    \n",
    "    query_emb = eval_model.encode(query, convert_to_tensor=True)\n",
    "    context_emb = eval_model.encode(context, convert_to_tensor=True)\n",
    "    similarity = util.cos_sim(query_emb, context_emb).item()\n",
    "    \n",
    "    relevance_scores.append(similarity)\n",
    "    print(f\"Query: {query[:50]}... → Score: {similarity:.3f}\")\n",
    "\n",
    "print(f\"\\n📊 Mean Context Relevance: {np.mean(relevance_scores):.3f}\")\n",
    "print(f\"   Range: [{np.min(relevance_scores):.3f}, {np.max(relevance_scores):.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7019eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ANSWER RELEVANCE\n",
      "============================================================\n",
      "Query: What is the punishment for murder?... → Score: 0.671\n",
      "Query: Explain Section 302 IPC... → Score: 0.619\n",
      "Query: What are the differences between theft and robbery... → Score: 0.753\n",
      "Query: Punishment for dowry death... → Score: 0.703\n",
      "Query: What is culpable homicide?... → Score: 0.693\n",
      "\n",
      "📊 Mean Answer Relevance: 0.688\n",
      "   Range: [0.619, 0.753]\n"
     ]
    }
   ],
   "source": [
    "# EVALUATION 4: ANSWER RELEVANCE\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANSWER RELEVANCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "relevance_scores = []\n",
    "\n",
    "for query in test_queries[:5]:\n",
    "    ipc_results = search_faiss(query, ipc_index, ipc_meta, top_k=2)\n",
    "    \n",
    "    context = \"Relevant IPC Sections:\\n\"\n",
    "    for sec in ipc_results:\n",
    "        context += f\"- Section {sec['section_no']}: {sec['Description']} (Punishment: {sec['punishment_raw']})\\n\"\n",
    "    \n",
    "    prompt = f\"User Query: {query}\\n\\n{context}\\n\\nBased on the above IPC sections, Name the sections relating to the user query and also list possible punishments.\"\n",
    "    answer = llm._call(prompt)\n",
    "    \n",
    "    query_emb = eval_model.encode(query, convert_to_tensor=True)\n",
    "    answer_emb = eval_model.encode(answer, convert_to_tensor=True)\n",
    "    similarity = util.cos_sim(query_emb, answer_emb).item()\n",
    "    \n",
    "    relevance_scores.append(similarity)\n",
    "    print(f\"Query: {query[:50]}... → Score: {similarity:.3f}\")\n",
    "\n",
    "print(f\"\\n📊 Mean Answer Relevance: {np.mean(relevance_scores):.3f}\")\n",
    "print(f\"   Range: [{np.min(relevance_scores):.3f}, {np.max(relevance_scores):.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04d3b6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FAITHFULNESS (Answer grounded in Context)\n",
      "============================================================\n",
      "Query: What is the punishment for murder?... → Score: 0.932\n",
      "Query: Explain Section 302 IPC... → Score: 0.926\n",
      "Query: What are the differences between theft and robbery... → Score: 0.945\n",
      "Query: Punishment for dowry death... → Score: 0.943\n",
      "Query: What is culpable homicide?... → Score: 0.956\n",
      "\n",
      "📊 Mean Faithfulness: 0.940\n",
      "   ✅ Answers well-grounded in context\n"
     ]
    }
   ],
   "source": [
    "# EVALUATION 5: FAITHFULNESS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FAITHFULNESS (Answer grounded in Context)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "faithfulness_scores = []\n",
    "\n",
    "for query in test_queries[:5]:\n",
    "    ipc_results = search_faiss(query, ipc_index, ipc_meta, top_k=2)\n",
    "    judg_results = search_faiss(query, judg_index, judg_meta, top_k=2)\n",
    "    \n",
    "    context = \"Relevant IPC Sections:\\n\"\n",
    "    for sec in ipc_results:\n",
    "        context += f\"- Section {sec['section_no']}: {sec['Description']} (Punishment: {sec['punishment_raw']})\\n\"\n",
    "    \n",
    "    context += \"\\nRelevant Judgements:\\n\"\n",
    "    for case in judg_results:\n",
    "        context += f\"- Case facts: {case['case_facts']}\\n\"\n",
    "    \n",
    "    prompt = f\"User Query: {query}\\n\\n{context}\\n\\nBased on the above IPC sections, Name the sections relating to the user query and also list possible punishments.\"\n",
    "    answer = llm._call(prompt)\n",
    "    \n",
    "    answer_emb = eval_model.encode(answer, convert_to_tensor=True)\n",
    "    context_emb = eval_model.encode(context, convert_to_tensor=True)\n",
    "    similarity = util.cos_sim(answer_emb, context_emb).item()\n",
    "    \n",
    "    faithfulness_scores.append(similarity)\n",
    "    print(f\"Query: {query[:50]}... → Score: {similarity:.3f}\")\n",
    "\n",
    "print(f\"\\n📊 Mean Faithfulness: {np.mean(faithfulness_scores):.3f}\")\n",
    "\n",
    "if np.mean(faithfulness_scores) > 0.7:\n",
    "    print(f\"   ✅ Answers well-grounded in context\")\n",
    "else:\n",
    "    print(f\"   ⚠️ Possible hallucination detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e02985f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BERTSCORE\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226eed2c0ebf4bb9bd34682c17798d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\ml\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\nihca\\.cache\\huggingface\\hub\\models--roberta-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd48f312eab41a687d83e96f966e060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08aa08caa7714c6290aee6dfe1a40377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f1a18e280364a38ae03a49987980bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8399b0db7ef40b393ac9e7671d9ab5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4f2ba0020b499d991655c087d59869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 BERTScore (Answer vs Context):\n",
      "   Precision: 0.834\n",
      "   Recall: 0.852\n",
      "   F1: 0.843\n",
      "   ✅ GOOD semantic similarity\n"
     ]
    }
   ],
   "source": [
    "# EVALUATION 6: BERTSCORE\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BERTSCORE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    from bert_score import score as bert_score\n",
    "    \n",
    "    generated_answers = []\n",
    "    contexts = []\n",
    "    \n",
    "    for query in test_queries[:5]:\n",
    "        ipc_results = search_faiss(query, ipc_index, ipc_meta, top_k=2)\n",
    "        \n",
    "        context = \"Relevant IPC Sections:\\n\"\n",
    "        for sec in ipc_results:\n",
    "            context += f\"- Section {sec['section_no']}: {sec['Description']} (Punishment: {sec['punishment_raw']})\\n\"\n",
    "        \n",
    "        prompt = f\"User Query: {query}\\n\\n{context}\\n\\nBased on the above IPC sections, Name the sections relating to the user query and also list possible punishments.\"\n",
    "        answer = llm._call(prompt)\n",
    "        \n",
    "        generated_answers.append(answer)\n",
    "        contexts.append(context)\n",
    "    \n",
    "    P, R, F1 = bert_score(generated_answers, contexts, lang='en', verbose=False)\n",
    "    \n",
    "    print(f\"\\n📊 BERTScore (Answer vs Context):\")\n",
    "    print(f\"   Precision: {P.mean().item():.3f}\")\n",
    "    print(f\"   Recall: {R.mean().item():.3f}\")\n",
    "    print(f\"   F1: {F1.mean().item():.3f}\")\n",
    "    \n",
    "    if F1.mean().item() > 0.7:\n",
    "        print(f\"   ✅ GOOD semantic similarity\")\n",
    "    else:\n",
    "        print(f\"   ⚠️ MODERATE semantic similarity\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"❌ Install: pip install bert-score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6b5f6dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LLM-AS-JUDGE (Google Gemini)\n",
      "============================================================\n",
      "\n",
      "💬 Answer:  Based on your user query, the relevant Indian Penal Code (IPC) section for murder is Section 302. The punishment for this crime includes:\n",
      "\n",
      "1. Death p...\n",
      "\n",
      "⚖️ Judge Response: ```json\n",
      "{\"relevance\": 4, \"faithfulness\": 5, \"legal_accuracy\": 4, \"completeness\": 3, \"clarity\": 5}\n",
      "```\n",
      "\n",
      "📊 Scores:\n",
      "   relevance: 4/5\n",
      "   faithfulness: 5/5\n",
      "   legal_accuracy: 4/5\n",
      "   completeness: 3/5\n",
      "   clarity: 5/5\n",
      "\n",
      "   Average: 4.20/5 ✅\n"
     ]
    }
   ],
   "source": [
    "# EVALUATION 7: LLM-AS-JUDGE (Using Google Gemini)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LLM-AS-JUDGE (Google Gemini)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Configure Gemini API (replace with your API key)\n",
    "GEMINI_API_KEY = \"AIzaSyDbxRX-ytJxp6yDmw2rQr8IHUNWnO4nB7w\"  # Get from https://makersuite.google.com/app/apikey\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "test_query = \"What is the punishment for murder?\"\n",
    "\n",
    "ipc_results = search_faiss(test_query, ipc_index, ipc_meta, top_k=2)\n",
    "context = \"Relevant IPC Sections:\\n\"\n",
    "for sec in ipc_results:\n",
    "    context += f\"- Section {sec['section_no']}: {sec['Description']} (Punishment: {sec['punishment_raw']})\\n\"\n",
    "\n",
    "prompt = f\"User Query: {test_query}\\n\\n{context}\\n\\nBased on the above IPC sections, Name the sections relating to the user query and also list possible punishments.\"\n",
    "answer = llm._call(prompt)\n",
    "\n",
    "judge_prompt = f\"\"\"You are an expert legal evaluator. Rate this Indian legal chatbot response.\n",
    "\n",
    "Query: {test_query}\n",
    "Context: {context}\n",
    "Answer: {answer}\n",
    "\n",
    "Rate 1-5 for: relevance, faithfulness, legal_accuracy, completeness, clarity\n",
    "\n",
    "Respond ONLY in JSON format (no markdown, no other text):\n",
    "{{\"relevance\": 4, \"faithfulness\": 5, \"legal_accuracy\": 4, \"completeness\": 3, \"clarity\": 5}}\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Call Gemini\n",
    "    model = genai.GenerativeModel('gemini-2.0-flash-lite')\n",
    "    judge_response = model.generate_content(judge_prompt)\n",
    "    judge_text = judge_response.text\n",
    "    \n",
    "    print(f\"\\n💬 Answer: {answer[:150]}...\")\n",
    "    print(f\"\\n⚖️ Judge Response: {judge_text}\")\n",
    "    \n",
    "    # Parse JSON\n",
    "    json_match = re.search(r'\\{.*\\}', judge_text, re.DOTALL)\n",
    "    if json_match:\n",
    "        scores = json.loads(json_match.group())\n",
    "        print(f\"\\n📊 Scores:\")\n",
    "        for key, value in scores.items():\n",
    "            print(f\"   {key}: {value}/5\")\n",
    "        avg_score = np.mean(list(scores.values()))\n",
    "        print(f\"\\n   Average: {avg_score:.2f}/5 {'✅' if avg_score >= 3.5 else '⚠️'}\")\n",
    "    else:\n",
    "        print(\"   ⚠️ Could not parse JSON from response\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Gemini API Error: {e}\")\n",
    "    print(\"   Make sure you've set GEMINI_API_KEY and installed: pip install google-generativeai\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
